{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7c1dc2",
   "metadata": {},
   "source": [
    "# Temperature Profile Classification - 2 Class system\n",
    "GMM classification of Southern Ocean Argo float temperature profile data. This notebook uses a previously created model, PCA and sample data.<br><br>\n",
    "### Dask import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2963a54",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dask server setup cell\n",
    "'''\n",
    "target_version='0.19.0'\n",
    "!pip install xarray=={target_version} --upgrade #--upgrade\n",
    "\n",
    "import logging\n",
    "import subprocess\n",
    "from dask.distributed import Client\n",
    "from dask_gateway import Gateway\n",
    "from distributed import WorkerPlugin\n",
    "\n",
    "import dask\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
    " \n",
    "class PipPlugin(WorkerPlugin):\n",
    "    \"\"\"\n",
    "    Install packages on a worker as it starts up.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    packages : List[str]\n",
    "        A list of packages to install with pip on startup.\n",
    "    \"\"\"\n",
    "    def __init__(self, packages):\n",
    "        self.packages = packages\n",
    " \n",
    "    def setup(self, worker):\n",
    "        logger = logging.getLogger(\"distributed.worker\")\n",
    "        subprocess.call(['python', '-m', 'pip', 'install', '--upgrade'] + self.packages)\n",
    "        logger.info(\"Installed %s\", self.packages)\n",
    "        \n",
    "def check():\n",
    "    import xarray\n",
    "    return xarray.__version__\n",
    "        \n",
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster(worker_memory=8)\n",
    "cluster.scale(20)\n",
    "client = Client(cluster)\n",
    "client\n",
    " \n",
    "plugin = PipPlugin([f'xarray=={target_version}'])\n",
    "client.register_worker_plugin(plugin)\n",
    "client.run(check)\n",
    "'''\n",
    "blank=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610deb0d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202468ad",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230b0c3",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a9e6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment data for analysis\n",
    "dataVariableId = 'thetao'\n",
    "dataExperimentId = 'historical'\n",
    "dataSourceId = 'UKESM1-0-LL'\n",
    "dataInstitutionId = 'MOHC'\n",
    "approvedIds = [\"r1i1p1f2\", \"r2i1p1f2\", \"r3i1p1f2\"] #insert start of approved member_ids\n",
    "\n",
    "#File imports\n",
    "maskName = \"OceanMaskVolcello\"\n",
    "modelName = \"GMM_UK_2Class_R1\"\n",
    "\n",
    "#Data definitions\n",
    "startDate = '1980-01'\n",
    "endDate = '2009-12'\n",
    "timeRange = slice(startDate, endDate)\n",
    "levSel = slice(0, 2000) #Selected levels to be investigated\n",
    "maxLat = -30 #Selected latitude to be investigated\n",
    "runIdSel = 0\n",
    "maskEnable = False #Decides if training data mask is applied, or if full data set is classified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1bbf7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f61e6",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4d1068",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import calendar\n",
    "#import cartopy.crs as ccrs\n",
    "#import cartopy.feature as cfeature\n",
    "import dask.dataframe as dd\n",
    "import fsspec\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib as mpl ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import xarray as xr\n",
    "import zarr\n",
    "\n",
    "from dask import config\n",
    "from dask import delayed\n",
    "from joblib import dump, load\n",
    "from matplotlib.pyplot import cm\n",
    "from sklearn import mixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "config.set(**{'array.slicing.split_large_chunks': True})\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a452bba",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224d2e6",
   "metadata": {},
   "source": [
    "### Importing data sets\n",
    "Importing the data for the models.\n",
    "\n",
    "<b>Import sample data set and corresponding time/geo data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820d80ab",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 UKESM1-0-LL data sets opened\n",
      "Data sets successfully merged and renamed into dataRaw. Data dimensions are Frozen({'RunId': 1, 'time': 1980, 'lev': 75, 'j': 330, 'i': 360}).\n"
     ]
    }
   ],
   "source": [
    "#Importing UK ESM data cell\n",
    "\n",
    "#Selecting data tables\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "dfFilt = df[df.variable_id.eq(dataVariableId) & df.experiment_id.eq(dataExperimentId) & df.source_id.eq(dataSourceId) & df.institution_id.eq(dataInstitutionId)]\n",
    "\n",
    "memberArr = np.empty(shape=(0), dtype=bool)\n",
    "for i in dfFilt[\"member_id\"]:\n",
    "    rowSel = i[:] in approvedIds #adapt i[:] to match size of approvedIds\n",
    "    memberArr = np.append(memberArr, rowSel)\n",
    "\n",
    "memberSer = pd.Series(memberArr, name='bools')\n",
    "dfFilt = dfFilt[memberSer.values]\n",
    "dfFilt = dfFilt[:1]\n",
    "\n",
    "#Opening and counting number of tables\n",
    "fileSetList = []\n",
    "for i in range(len(dfFilt)):\n",
    "    zstore = dfFilt.zstore.values[i]\n",
    "    mapper = fsspec.get_mapper(zstore)\n",
    "    fileRaw = xr.open_zarr(mapper, consolidated=True)\n",
    "    fileSetList.append(fileRaw)\n",
    "fileCount = len(fileSetList)\n",
    "if fileCount:\n",
    "    print(str(fileCount)+\" \"+dataSourceId+\" data sets opened\")\n",
    "else:\n",
    "    print(\"No UKESM data sets opened\")\n",
    "    \n",
    "#Formatting dates into np.datetime64 format\n",
    "for i in range(fileCount): \n",
    "    startDateIterate = np.datetime64(fileSetList[i]['time'].values[0],'M')\n",
    "    endDateIterate = np.datetime64(fileSetList[i]['time'].values[-1],'M') + np.timedelta64(1,'M')\n",
    "    fileSetList[i]['time']=('time', np.arange(startDateIterate, endDateIterate, dtype='datetime64[M]'))\n",
    "    fileSetList[i]['time_bnds']=('time_bnds', np.arange(startDateIterate, endDateIterate, dtype='datetime64[M]')) \n",
    "fileSet = xr.combine_nested(fileSetList, concat_dim='RunId') #Combining data sets\n",
    "\n",
    "dataRaw = fileSet.thetao\n",
    "try: #Adjusting array names\n",
    "    dataRaw = dataRaw.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Data sets successfully merged and renamed into dataRaw. Data dimensions are \"+str(dataRaw.sizes)+\".\")\n",
    "#dataRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d704971c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM data loaded and stored in dfESMLatLevT. Data dimensions are Frozen({'time': 360, 'lev': 54, 'j': 139, 'i': 360}).\n"
     ]
    }
   ],
   "source": [
    "#UK ESM raw processing cell\n",
    "dfESMLev = dataRaw.sel(lev=levSel) #Selects level data down to 2k\n",
    "dfESMLevT = dfESMLev.sel(time=timeRange)\n",
    "dfESMLatLevT = dfESMLevT.where(dfESMLevT.lat < maxLat, drop=True) #Selection of latitude\n",
    "dfESMLatLevT = dfESMLatLevT.squeeze()\n",
    "#dfESMLatLevT = dfESMLatLevT.reset_coords(drop=True) #Removes lev if single value\n",
    "\n",
    "globalStartDate = dfESMLatLevT[\"time\"][0].values\n",
    "globalDateInc = dfESMLatLevT[\"time\"][1].values - globalStartDate\n",
    "#np.datetime64(globalDateInc,'D')\n",
    "globalEndDateIn = dfESMLatLevT[\"time\"][-1].values\n",
    "globalEndDateOut = globalEndDateIn + globalDateInc\n",
    "\n",
    "globalStartDateStr = str(globalStartDate)[:7]\n",
    "globalEndDateInStr = str(globalEndDateIn)[:7]\n",
    "globalEndDateOutStr = str(globalEndDateOut)[:7]\n",
    "\n",
    "print(\"UKESM data loaded and stored in dfESMLatLevT. Data dimensions are \"+str(dfESMLatLevT.sizes)+\".\")\n",
    "#dfESMLatLevT #Uncomment to see data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf63dca",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Loading ocean Masks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd688a7",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask Loaded and stored in oceanMask and oceanMask2 (volcello and UKESM).\n"
     ]
    }
   ],
   "source": [
    "#Ocean mask import cell\n",
    "maskFile = xr.open_dataset(maskName)\n",
    "oceanMask = maskFile.to_array()\n",
    "maskFile = xr.open_dataset(\"OceanMaskUKESM1\")\n",
    "oceanMask2 = maskFile.to_array()\n",
    "print(\"Mask Loaded and stored in oceanMask and oceanMask2 (volcello and UKESM).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff8060",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Unpacking ocean masks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b0f0d9",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocean mask unpacked into geoRangeFilt.\n",
      "UKESM Ocean mask unpacked into geoRangeFilt2.\n"
     ]
    }
   ],
   "source": [
    "#Mask unpacking cell\n",
    "geoRange = oceanMask #copying mask\n",
    "geoRange = geoRange.rename({\"variable\":\"cleanMe\"}) #Dimension removal\n",
    "geoRange = geoRange.sel(cleanMe = geoRange.cleanMe.values[0]) #Dimension removal\n",
    "geoRange = geoRange.reset_coords(\"cleanMe\", drop=True) #Dimension removal\n",
    "geoRangeS = geoRange.stack(ij =(\"i\", \"j\")) #Stacking\n",
    "geoRangeFilt = geoRangeS.dropna(\"ij\")\n",
    "print(\"Ocean mask unpacked into geoRangeFilt.\")\n",
    "\n",
    "geoRange2 = oceanMask2 #copying mask\n",
    "geoRange2S = geoRange2.stack(ij =(\"i\", \"j\")) #Stacking\n",
    "geoRangeFilt2 = geoRange2S.dropna(\"ij\")\n",
    "print(\"UKESM Ocean mask unpacked into geoRangeFilt2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd3c7c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Date Calculations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b59086c",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated date range.\n"
     ]
    }
   ],
   "source": [
    "#Date calculation cell\n",
    "startDateNp = np.datetime64(startDate, 'M')\n",
    "endDateNp = np.datetime64(endDate, 'M')\n",
    "timeDiff = endDateNp - startDateNp\n",
    "timeDiff = timeDiff.astype(int) + 1\n",
    "print(\"Calculated date range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa8740",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5dbebb",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "<li>pickRand - Takes in data frame and returns sampled data frame with a randomly selected number of rows from the input data frame, controled by the second input variable to the function.\n",
    "<li>storeMeta - Returns a np array containing the latitude and longitude data for an input xarray and associated ij.\n",
    "<li>loadModel - loadeds and returns GMM model named in input.\n",
    "<li>saveModel - saves input GMM model to provided name, if no name provided default is GMMGenerated.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba921db",
   "metadata": {
    "code_folding": [
     0,
     1,
     18,
     37,
     48,
     60
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "def pickRand(dataArray, sampleFactor):\n",
    "    '''Returns a sample of the input array, size of sampled array is based on sampleFactor. For factor > 1 that many points are chosen, for factor < 1 that % is taken of the array'''\n",
    "    arrLen = len(dataArray)\n",
    "    if sampleFactor > 1:\n",
    "        sampleSize = int(sampleFactor)\n",
    "    elif sampleFactor > 0:\n",
    "        sampleSize = int(sampleFactor*arrLen)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    filtArr = np.zeros(arrLen, dtype=bool) # empty mask\n",
    "    sampleId = np.random.choice(arrLen, sampleSize, False) # np array of randomly generated non repeating numbers\n",
    "    for i in sampleId:\n",
    "        filtArr[i] = True # populating mask\n",
    "    return dataArray[filtArr] # applies mask\n",
    "\n",
    "\n",
    "def pickRandMask(maskLen, maskQuantity, sampleFactor):\n",
    "    '''Returns a linear mask for the input dimensions, size of mask is based on sampleFactor. For factor > 1 that many points are chosen, for factor < 1 that % is taken of the array'''\n",
    "    if sampleFactor > 1:\n",
    "        sampleSize = int(sampleFactor)\n",
    "    elif sampleFactor > 0:\n",
    "        sampleSize = int(sampleFactor*maskLen)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    globalArr = np.empty(shape=(0), dtype=bool)\n",
    "    for i in range(maskQuantity):\n",
    "        filtArr = np.zeros(maskLen, dtype=bool) # empty mask\n",
    "        sampleId = np.random.choice(maskLen, sampleSize, False) # np array of randomly generated non repeating numbers\n",
    "        for j in sampleId:\n",
    "            filtArr[j] = True # populating mask\n",
    "        globalArr = np.append(globalArr, filtArr)\n",
    "    return globalArr\n",
    "\n",
    "\n",
    "def storeMeta(dataArray):\n",
    "    '''Returns a np array containing the latitude and longitude data for the input xarray and the associated ij index'''\n",
    "    storeLen = len(dataArray[\"lat\"]) # assumes each lat has a corresponding lon\n",
    "    storage = np.empty(shape=(0,storeLen))\n",
    "    storage = np.append(storage, [dataArray[\"lat\"].values], axis = 0)\n",
    "    storage = np.append(storage, [dataArray[\"lon\"].values], axis = 0)\n",
    "    #storage = np.append(storage, [dataArray[\"time\"].values], axis = 0)\n",
    "    #storage = np.append(storage, [dataArray[\"ij\"].values], axis = 0)\n",
    "    return storage\n",
    "\n",
    "\n",
    "def loadModel(modelName:str):\n",
    "    '''Loades the input GMM model named in the functions input. Returns loaded model.'''\n",
    "    means = np.load(modelName + '_means.npy')\n",
    "    covar = np.load(modelName + '_covariances.npy')\n",
    "    GMModel = mixture.GaussianMixture(n_components = len(means), covariance_type='full')\n",
    "    GMModel.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "    GMModel.weights_ = np.load(modelName + '_weights.npy')\n",
    "    GMModel.means_ = means\n",
    "    GMModel.covariances_ = covar\n",
    "    return GMModel\n",
    "\n",
    "\n",
    "def saveModel(GMModel, modelName = \"GMMGenerated\"):\n",
    "    '''Saves the input GMM model's weights, means and covariances. Assigns input name if provided to model.'''\n",
    "    GMModel_name = str(modelName)\n",
    "    np.save(modelName + '_weights', GMModel.weights_, allow_pickle=False)\n",
    "    np.save(modelName + '_means', GMModel.means_, allow_pickle=False)\n",
    "    np.save(modelName + '_covariances', GMModel.covariances_, allow_pickle=False)\n",
    "    return 0\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe44f97",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb12311",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "<li> bicPlot - Plots BIC score array against component number.\n",
    "<li> locationPlotGroup - plots location and classification of data points for an input numpy array.\n",
    "<li> locationPlotGroupDF - plots location and classification of data points for an input data frame.\n",
    "<li> locationPlotGroupDFMonthly - plots location and classification of data points for an input data frame in monthly subplots.\n",
    "<li> locationPlotTime - plots locations of an input data array on a map with a colour scale for time.\n",
    "<li> locationPlotUncertaintyDF - plots uncertainty in classification on a location plot.\n",
    "<li> tempPointPlot - Plots the temperature profile of a single point against depth.\n",
    "<li> tempGroupPlot - Plots the mean/+-1std temperature profiles of all classes in input dataArrays (seperate mean and std).\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66336863",
   "metadata": {
    "code_folding": [
     0,
     3,
     25,
     39,
     56,
     70,
     89,
     106,
     120,
     140,
     153,
     166,
     175
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "sampleDepthAxis = dfESMLatLevT[\"lev\"]\n",
    "\n",
    "def bicPlot(bicArray, startNo, endNo, skipNo, title, label, plotNo):\n",
    "    '''Plots input BIC score array'''\n",
    "    plt.figure(plotNo, figsize=(20, 8))\n",
    "    plt.style.use(\"seaborn-darkgrid\")\n",
    "    componentRange = range(startNo, endNo, skipNo)\n",
    "    plt.plot(componentRange, bicArray, label = str(label))\n",
    "    \n",
    "    bicArrayMax = np.max(bicArray)\n",
    "    bicArrayMin = np.min(bicArray)\n",
    "    bicRange = bicArrayMax-bicArrayMin\n",
    "    if bicRange == 0:\n",
    "        bicRange = 20 #provides border 1 if all bic values are identical\n",
    "    plt.xticks(componentRange)\n",
    "    plt.xlim([startNo-0.5, endNo+0.5])\n",
    "    plt.ylim([bicArrayMin-0.05*bicRange, bicArrayMax+0.05*bicRange])\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel(\"Number of components\")\n",
    "    plt.ylabel(\"BIC score\")\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "def locationPlotGroup(metaDataArray, size, plotNo):\n",
    "    '''Plots locations of numpy arrays with group colour scheme'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(metaDataArray[1], metaDataArray[0], transform=ccrs.PlateCarree(), c =  metaDataArray[3], cmap='RdBu_r')\n",
    "    cb = plt.colorbar(im)\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(\"Grouped Sample Locations (\"+str(len(metaDataArray[0]))+\")\")\n",
    "\n",
    "\n",
    "def locationPlotGroupDFTime(dataFrame, title, size, plotNo):\n",
    "    '''Plots locations of data frame points with group colour scheme'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataFrame[\"lon\"], dataFrame[\"lat\"], transform=ccrs.PlateCarree(), c =  mdates.date2num(dataFrame[\"time\"]), cmap='brg')\n",
    "    cb = plt.colorbar(im)\n",
    "    loc = mdates.AutoDateLocator()\n",
    "    cb.ax.yaxis.set_major_locator(loc)\n",
    "    cb.ax.yaxis.set_major_formatter(mdates.ConciseDateFormatter(loc))\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(str(title))\n",
    "    \n",
    "    \n",
    "def locationPlotGroupDFLab(dataFrame, title, size, plotNo):\n",
    "    '''Plots locations of data frame points with group colour scheme'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataFrame[\"lon\"], dataFrame[\"lat\"], transform=ccrs.PlateCarree(), c =  dataFrame[\"labelSorted\"], cmap='RdBu_r')\n",
    "    cb = plt.colorbar(im)\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(str(title))\n",
    "\n",
    "\n",
    "def locationPlotGroupDFMonthly(dataFrame, title, plotNo):\n",
    "    '''Plots locations of dataframe points by monthly subplot with group colour scheme'''\n",
    "    fig = plt.figure(plotNo, figsize=(30,42))\n",
    "    plt.title(str(title))\n",
    "    for i in range(1, 13):\n",
    "        timeData = dataFrame.where(dataFrame[\"time\"].dt.month==i)\n",
    "        ax = plt.subplot(4, 3, i, projection=ccrs.SouthPolarStereo())\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.coastlines()\n",
    "        ax.gridlines()\n",
    "        im = ax.scatter(timeData[\"lon\"], timeData[\"lat\"], transform=ccrs.PlateCarree(), c =  timeData[\"labelSorted\"], cmap='RdBu_r')\n",
    "        plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "        plt.title(calendar.month_abbr[i]) \n",
    "    plt.subplots_adjust(wspace=0, hspace=0.05)\n",
    "    cb_ax = fig.add_axes([0.27, 0.1, 0.5, 0.02])\n",
    "    cbar = fig.colorbar(im, cax=cb_ax, orientation=\"horizontal\")\n",
    "\n",
    "\n",
    "def locationPlotTime(dataArray, size, plotNo):\n",
    "    '''Plots locations of numpy arrays with date colour scheme'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataArray[1], dataArray[0], transform=ccrs.PlateCarree(), c= mdates.date2num(dataArray[2]), cmap='brg')\n",
    "    cb = plt.colorbar(im)\n",
    "    loc = mdates.AutoDateLocator()\n",
    "    cb.ax.yaxis.set_major_locator(loc)\n",
    "    cb.ax.yaxis.set_major_formatter(mdates.ConciseDateFormatter(loc))\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(\"Sample Locations (\"+str(len(dataArray[0]))+\")\")\n",
    "\n",
    "\n",
    "def locationPlotUncertaintyDF(dataFrame, title, size, plotNo):\n",
    "    '''Plots input data array classification uncertainties'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataFrame[\"lon\"], dataFrame[\"lat\"], transform=ccrs.PlateCarree(), c =  dataFrame[\"classUncertainty\"], cmap='Blues')\n",
    "    cb = plt.colorbar(im)\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(str(title))\n",
    "\n",
    "\n",
    "def locationPlotUncertaintyDFMonthly(dataFrame, title, plotNo):\n",
    "    '''Plots locations of dataframe points by monthly subplot with group colour scheme'''\n",
    "    fig = plt.figure(plotNo, figsize=(30,42))\n",
    "    plt.title(str(title))\n",
    "    for i in range(1, 13):\n",
    "        timeData = dataFrame.where(dataFrame[\"time\"].dt.month==i)\n",
    "        ax = plt.subplot(4, 3, i, projection=ccrs.SouthPolarStereo())\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.coastlines()\n",
    "        ax.gridlines()\n",
    "        im = ax.scatter(timeData[\"lon\"], timeData[\"lat\"], transform=ccrs.PlateCarree(), c =  timeData[\"classUncertainty\"], cmap='Blues', vmin=0, vmax=1)\n",
    "        #cb = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "        plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "        plt.title(calendar.month_abbr[i]) \n",
    "    plt.subplots_adjust(wspace=0, hspace=0.05)\n",
    "    cb_ax = fig.add_axes([0.27, 0.1, 0.5, 0.02])\n",
    "    cbar = fig.colorbar(im, cax=cb_ax, orientation=\"horizontal\")\n",
    "\n",
    "\n",
    "def locationPlotXr(dataArray, size, plotNo):\n",
    "    '''Plots locations of numpy arrays with date colour scheme'''\n",
    "    plt.figure(plotNo, figsize=size)\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataArray[\"lon\"], dataArray[\"lat\"], transform=ccrs.PlateCarree())\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(\"Sample Locations (\"+str(len(dataArray[\"lat\"]))+\")\")        \n",
    "    \n",
    "    \n",
    "def surfaceTempPlot(dataArray, plotNo):\n",
    "    plt.figure(plotNo, figsize=(20,20))\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    im = ax.scatter(dataArray[\"lon\"], dataArray[\"lat\"], transform=ccrs.PlateCarree(), c =  dataArray[surfaceLevName], cmap='RdBu_r')\n",
    "    cb = plt.colorbar(im)\n",
    "    plt.plot(np.arange(0,361,1),np.ones(361)*-29.5, transform=ccrs.PlateCarree(), color=\"Black\")\n",
    "    plt.title(\"Surface Temperature of Samples\")\n",
    "\n",
    "\n",
    "def tempPointPlot(dataArray, label, title, plotNo):\n",
    "    '''Displays temperature profile plot for a given data set, singular point'''\n",
    "    plt.figure(plotNo)\n",
    "    plt.plot(dataArray, sampleDepthAxis, label = label)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(str(title))\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "def tempGroupProfile(dataArrayMean, dataArrayStd, plotNo):\n",
    "    '''Displays mean /+-1 std temperature profiles for classes in dataArrayMean and dataArrayStd. Requires sampleDepthAxis'''\n",
    "    dataCompNo = len(dataArrayMean)   \n",
    "    columnNames = sampleDFSortMeans.columns.values\n",
    "    dataStart = np.where(columnNames == sampleDepthAxis[0].values)[0][0]\n",
    "    subPlotX = int(np.ceil(dataCompNo/5))\n",
    "    \n",
    "    plt.figure(plotNo, figsize=(35, 10*subPlotX))\n",
    "    plt.style.use(\"seaborn-darkgrid\")\n",
    "    palette = cm.coolwarm(np.linspace(0,1, dataCompNo))\n",
    "    \n",
    "    for i in range(dataCompNo):\n",
    "        meanT = dataArrayMean.iloc[i, dataStart:].to_numpy()\n",
    "        stdT = dataArrayStd.iloc[i, dataStart:].to_numpy()\n",
    "        \n",
    "        plt.subplot(subPlotX, 5, i+1)\n",
    "        plt.plot(meanT, sampleDepthAxis, marker='', linestyle=\"solid\", color=palette[i], linewidth=6.0, alpha=0.9)\n",
    "        plt.plot(meanT+stdT, sampleDepthAxis, marker='', linestyle=\"dashed\", color=palette[i], linewidth=6.0, alpha=0.9)\n",
    "        plt.plot(meanT-stdT, sampleDepthAxis, marker='', linestyle=\"dashed\", color=palette[i], linewidth=6.0, alpha=0.9)\n",
    "        \n",
    "        plt.xlim([-2,20])\n",
    "        plt.ylim([0,1000])\n",
    "        ax = plt.gca()\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True)\n",
    "        \n",
    "        fs = 16 #font size\n",
    "        plt.xlabel(\"Temperature (°C)\", fontsize=fs)\n",
    "        plt.ylabel(\"Depth (m)\", fontsize=fs)\n",
    "        plt.title(\"Class = \"+str(i), fontsize=fs)\n",
    "        mpl.rc(\"xtick\", labelsize=fs)\n",
    "        mpl.rc(\"ytick\", labelsize=fs)\n",
    "        \n",
    "        '''\n",
    "        textstr = '\\n'.join((\n",
    "            r'N profs. = %i' % (nprofs[nrow], ),\n",
    "            r'Mean lon = %i' % (meanLon, ),\n",
    "            r'Mean lat = %i' % (meanLat, ),\n",
    "            r'Post. = %i' % (meanMaxPP, )))\n",
    "        props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8)\n",
    "        ax.text(0.45, 0.25, textstr, transform=ax.transAxes, fontsize=fs, verticalalignment='top', bbox=props)\n",
    "        '''\n",
    "\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a11ef",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70311e8",
   "metadata": {},
   "source": [
    "### Plotting Ocean Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8623ab",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Mask plotting cell\n",
    "#locationPlotXr(geoRangeFilt, (10,10), 1) #OceanMaskVolcello\n",
    "#locationPlotXr(geoRangeFilt2, (10,10), 2) #OceanMaskUKESM1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4026ed",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8a300",
   "metadata": {},
   "source": [
    "### Generating Data Samples\n",
    "<b>Identifying, masking and stacking raw data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c703c272",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data identified, stacked and stored in dfESMLatLevTStackFilt. Data dimensions: Frozen({'time': 360, 'ij': 22194, 'lev': 54}).\n"
     ]
    }
   ],
   "source": [
    "#Identifying, masking and stacking raw data cell\n",
    "dfESMLatLevTStack = dfESMLatLevT.stack(ij =(\"i\", \"j\"))\n",
    "dfESMLatLevTStack = dfESMLatLevTStack.transpose('time', 'ij', 'lev')\n",
    "dfESMLatLevTStackFilt = dfESMLatLevTStack.sel(ij = geoRangeFilt.ij.values) #Produces 22194\n",
    "dfESMLatLevTStackFilt\n",
    "print(\"Raw data identified, stacked and stored in dfESMLatLevTStackFilt. Data dimensions: \"+str(dfESMLatLevTStackFilt.sizes)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "135177d4",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Plotting raw data locations cell\n",
    "#locationPlotXr(dfESMLatLevTStackFilt, (10,10), 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d6150",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Selecting sample data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90dd28e7",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mask loaded.\n"
     ]
    }
   ],
   "source": [
    "#Mask loading cell\n",
    "if maskEnable:\n",
    "    importName = modelName + \"_Mask.npy\"\n",
    "    mask = np.load(importName)\n",
    "    print(\"Data mask loaded from \"+ importName +\".\")\n",
    "else:\n",
    "    print(\"No mask loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4e67bc",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data calculated and stored in sampleData. Sample data dimensions: Frozen({'ijT': 7989840, 'lev': 54}).\n"
     ]
    }
   ],
   "source": [
    "#Selecting sample data cell\n",
    "sampleDataRaw = dfESMLatLevTStackFilt.reset_index('ij')\n",
    "sampleDataRaw = sampleDataRaw.stack(ijT = ('time', 'ij'))\n",
    "\n",
    "if maskEnable:\n",
    "    sampleData = sampleDataRaw[:,mask] #Training data mask applied\n",
    "else:\n",
    "    sampleData = sampleDataRaw #Full data set to be classified\n",
    "\n",
    "sampleData = sampleData.transpose('ijT', 'lev')\n",
    "print(\"Sample data calculated and stored in sampleData. Sample data dimensions: \"+str(sampleData.sizes)+\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946ca0c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Placing sample data in tables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597cf15a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample lat, lon and time converted to datafile (sampleMetaDF). 7989840 samples identified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-66.111519</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.703316</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.288567</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-64.867195</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-64.439102</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon       time\n",
       "0 -66.111519  73.5 1980-01-01\n",
       "1 -65.703316  73.5 1980-01-01\n",
       "2 -65.288567  73.5 1980-01-01\n",
       "3 -64.867195  73.5 1980-01-01\n",
       "4 -64.439102  73.5 1980-01-01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Location and time data to table cell\n",
    "metaData = {\"lat\":sampleData[\"lat\"], \"lon\":sampleData[\"lon\"], \"time\":sampleData[\"time\"]}\n",
    "sampleMetaDF = pd.DataFrame(metaData, columns=[\"lat\", \"lon\", \"time\"])\n",
    "print(\"Sample lat, lon and time converted to datafile (sampleMetaDF). \"+str(len(sampleMetaDF))+\" samples identified.\")\n",
    "sampleMetaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28692e94",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleData converted to datafile (sampleDataDF).  Datafiles combined into sampleDF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>0.5057600140571594</th>\n",
       "      <th>1.5558552742004395</th>\n",
       "      <th>2.6676816940307617</th>\n",
       "      <th>3.8562798500061035</th>\n",
       "      <th>5.140361309051514</th>\n",
       "      <th>6.543033599853516</th>\n",
       "      <th>8.09251880645752</th>\n",
       "      <th>...</th>\n",
       "      <th>856.678955078125</th>\n",
       "      <th>947.4478759765625</th>\n",
       "      <th>1045.854248046875</th>\n",
       "      <th>1151.9912109375</th>\n",
       "      <th>1265.8614501953125</th>\n",
       "      <th>1387.376953125</th>\n",
       "      <th>1516.3636474609375</th>\n",
       "      <th>1652.5684814453125</th>\n",
       "      <th>1795.6707763671875</th>\n",
       "      <th>1945.2955322265625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-66.111519</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>-1.584012</td>\n",
       "      <td>-1.583307</td>\n",
       "      <td>-1.586312</td>\n",
       "      <td>-1.589255</td>\n",
       "      <td>-1.592438</td>\n",
       "      <td>-1.596716</td>\n",
       "      <td>-1.602287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326054</td>\n",
       "      <td>0.293914</td>\n",
       "      <td>0.235124</td>\n",
       "      <td>0.175954</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>0.117106</td>\n",
       "      <td>0.100809</td>\n",
       "      <td>0.081946</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.049921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.703316</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>-1.632348</td>\n",
       "      <td>-1.632239</td>\n",
       "      <td>-1.635037</td>\n",
       "      <td>-1.637914</td>\n",
       "      <td>-1.639803</td>\n",
       "      <td>-1.641319</td>\n",
       "      <td>-1.642947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338328</td>\n",
       "      <td>0.299162</td>\n",
       "      <td>0.243444</td>\n",
       "      <td>0.192133</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0.124804</td>\n",
       "      <td>0.104497</td>\n",
       "      <td>0.085212</td>\n",
       "      <td>0.070267</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.288567</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>-1.604592</td>\n",
       "      <td>-1.609563</td>\n",
       "      <td>-1.617265</td>\n",
       "      <td>-1.624262</td>\n",
       "      <td>-1.629788</td>\n",
       "      <td>-1.634277</td>\n",
       "      <td>-1.637870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356454</td>\n",
       "      <td>0.314596</td>\n",
       "      <td>0.264908</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>0.178470</td>\n",
       "      <td>0.141546</td>\n",
       "      <td>0.114856</td>\n",
       "      <td>0.092878</td>\n",
       "      <td>0.075004</td>\n",
       "      <td>0.057517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-64.867195</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>-1.576928</td>\n",
       "      <td>-1.586567</td>\n",
       "      <td>-1.599237</td>\n",
       "      <td>-1.609841</td>\n",
       "      <td>-1.618202</td>\n",
       "      <td>-1.624805</td>\n",
       "      <td>-1.629594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391538</td>\n",
       "      <td>0.349395</td>\n",
       "      <td>0.303209</td>\n",
       "      <td>0.256768</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.171921</td>\n",
       "      <td>0.137638</td>\n",
       "      <td>0.109580</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.067385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-64.439102</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>-1.574742</td>\n",
       "      <td>-1.585120</td>\n",
       "      <td>-1.596939</td>\n",
       "      <td>-1.606296</td>\n",
       "      <td>-1.614212</td>\n",
       "      <td>-1.620101</td>\n",
       "      <td>-1.624295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455728</td>\n",
       "      <td>0.410390</td>\n",
       "      <td>0.363946</td>\n",
       "      <td>0.316337</td>\n",
       "      <td>0.268540</td>\n",
       "      <td>0.221310</td>\n",
       "      <td>0.178075</td>\n",
       "      <td>0.140615</td>\n",
       "      <td>0.109725</td>\n",
       "      <td>0.084378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon       time  0.5057600140571594  1.5558552742004395  \\\n",
       "0 -66.111519  73.5 1980-01-01           -1.584012           -1.583307   \n",
       "1 -65.703316  73.5 1980-01-01           -1.632348           -1.632239   \n",
       "2 -65.288567  73.5 1980-01-01           -1.604592           -1.609563   \n",
       "3 -64.867195  73.5 1980-01-01           -1.576928           -1.586567   \n",
       "4 -64.439102  73.5 1980-01-01           -1.574742           -1.585120   \n",
       "\n",
       "   2.6676816940307617  3.8562798500061035  5.140361309051514  \\\n",
       "0           -1.586312           -1.589255          -1.592438   \n",
       "1           -1.635037           -1.637914          -1.639803   \n",
       "2           -1.617265           -1.624262          -1.629788   \n",
       "3           -1.599237           -1.609841          -1.618202   \n",
       "4           -1.596939           -1.606296          -1.614212   \n",
       "\n",
       "   6.543033599853516  8.09251880645752  ...  856.678955078125  \\\n",
       "0          -1.596716         -1.602287  ...          0.326054   \n",
       "1          -1.641319         -1.642947  ...          0.338328   \n",
       "2          -1.634277         -1.637870  ...          0.356454   \n",
       "3          -1.624805         -1.629594  ...          0.391538   \n",
       "4          -1.620101         -1.624295  ...          0.455728   \n",
       "\n",
       "   947.4478759765625  1045.854248046875  1151.9912109375  1265.8614501953125  \\\n",
       "0           0.293914           0.235124         0.175954            0.151899   \n",
       "1           0.299162           0.243444         0.192133            0.159579   \n",
       "2           0.314596           0.264908         0.217516            0.178470   \n",
       "3           0.349395           0.303209         0.256768            0.213219   \n",
       "4           0.410390           0.363946         0.316337            0.268540   \n",
       "\n",
       "   1387.376953125  1516.3636474609375  1652.5684814453125  1795.6707763671875  \\\n",
       "0        0.117106            0.100809            0.081946            0.069353   \n",
       "1        0.124804            0.104497            0.085212            0.070267   \n",
       "2        0.141546            0.114856            0.092878            0.075004   \n",
       "3        0.171921            0.137638            0.109580            0.086963   \n",
       "4        0.221310            0.178075            0.140615            0.109725   \n",
       "\n",
       "   1945.2955322265625  \n",
       "0            0.049921  \n",
       "1            0.052632  \n",
       "2            0.057517  \n",
       "3            0.067385  \n",
       "4            0.084378  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Temperature data to table and table merging cell\n",
    "#Generating surface temperature level value and column name\n",
    "surfaceLev = sampleData[\"lev\"][0].values\n",
    "surfaceData = sampleData.sel(lev = surfaceLev)\n",
    "surfaceLevName = \"Surface Temp (\"+str(np.round(surfaceLev,2))+\")\"\n",
    "\n",
    "#Exporting sample data into pandas\n",
    "if True:\n",
    "    sampleDataDF = sampleData.to_pandas()\n",
    "    sampleDataDFClean = sampleDataDF.reset_index()\n",
    "    sampleDataDFClean = sampleDataDFClean.drop(columns=['ij'])\n",
    "    sampleDF = pd.concat([sampleMetaDF, sampleDataDFClean.drop(columns=[\"time\"])], axis=1) #Removes time from second table for merge\n",
    "else:\n",
    "    sampleDF = sampleMetaDF\n",
    "    \n",
    "sampleDF[\"time\"] = pd.to_datetime(sampleDF[\"time\"])\n",
    "print(\"SampleData converted to datafile (sampleDataDF).  Datafiles combined into sampleDF.\")\n",
    "sampleDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb22b3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4dd1f1",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "<b>Scaling implementation</b><br>\n",
    "Applying scaling to the data set, ensuring all levels have same influence over data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64eb41e4",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16396/338934029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimportName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_Scaler\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscalerLoad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msampleDataScaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscalerLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampleData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scaling of sampleData complete using \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mscalerName\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\", stored in sampleDataScaled.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[0;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xarray\\core\\common.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDTypeLike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xarray\\core\\dataarray.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;34m\"\"\"The array's data as a numpy.ndarray\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xarray\\core\\variable.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;34m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_as_array_or_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xarray\\core\\variable.py\u001b[0m in \u001b[0;36m_as_array_or_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mTODO\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0monce\u001b[0m \u001b[0mthese\u001b[0m \u001b[0missues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \"\"\"\n\u001b[1;32m--> 262\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcupy_array_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"M\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\array\\core.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1503\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\threaded.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiprocessingPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     results = get_async(\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_workers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"waiting\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ready\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"running\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m                 \u001b[0mfire_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                         \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ellaw\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Scaler loading and transform cell\n",
    "importName = modelName + \"_Scaler\"\n",
    "scalerLoad = load(importName)\n",
    "sampleDataScaled = scalerLoad.transform(sampleData)\n",
    "print(\"Scaling of sampleData complete using \"+ scalerName +\", stored in sampleDataScaled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1dfa",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Scaling comparison</b><br>\n",
    "Comparing raw temperature profiles with their scaled equivalent. To show individual plots set solo to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4767c01",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Scaled temperature profile plotting cell\n",
    "solo = False #Set to true for seperate plots, false for combined plots.\n",
    "for i in range(5):\n",
    "    x = np.random.randint(len(sampleMetaDF))\n",
    "    tempPointPlot(sampleData[x], x, \"sample raw \"+str(x), solo*2*i)\n",
    "    tempPointPlot(sampleDataScaled[x], x, \"sample scaled \"+str(x), solo*2*i+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df9715",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72188c33",
   "metadata": {},
   "source": [
    "### Principle Component Analysis\n",
    "This process is performed to reduce the number of dimensions of the the data, as well as to improve overall model\n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA importing cell\n",
    "importName = modelName + \"_PCA.pkl\"\n",
    "pca = pk.load(open(importName, \"rb\"))\n",
    "print(\"PCA loaded into pca.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789f8c2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#PCA transform cell\n",
    "sampleDataScaledPCA = pca.transform(sampleDataScaled) #converting input data into PCA representation\n",
    "print(\"Data passed through PCA to sampleDataPCA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d98888",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e7364",
   "metadata": {},
   "source": [
    "### Model import/BIC score calculation\n",
    "The previously generated model is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d6011",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Model import and BIC + Component Calculation Cell\n",
    "bestGMModel = loadModel(modelName) #Loading model\n",
    "bicMin = bestGMModel.bic(sampleDataScaledPCA) #BIC score calculation\n",
    "bicComponentMin = bestGMModel.n_components #Identifying number of components in model (2 for this notebook)\n",
    "\n",
    "print(\"Model \"+modelName+\" loaded. The bicScore was \"+str(np.round(bicMin, 2))+\" for \"+str(bicComponentMin)+\".\")\n",
    "print(\"Imported model \"+modelName+\" in use. No calculations necessary.\")\n",
    "print(\"Imported model \"+modelName+\" in use. Model BIC score for training data: \"+str(bicMin)+\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2e6b1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db64938",
   "metadata": {},
   "source": [
    "### Assigning class labels to each profile using the best GMM\n",
    "Implementation of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d8266",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Classification and classification probability cell\n",
    "labels = bestGMModel.predict(sampleDataScaledPCA) #Assignment of class labels from best GMM\n",
    "posteriorProbs = bestGMModel.predict_proba(sampleDataScaledPCA) #Probability of profile belonging in class\n",
    "maxPosteriorProbs = np.max(posteriorProbs, axis=1) #Evaluating assigned class probability\n",
    "classUncertainty = 2 - 2*maxPosteriorProbs #I factor calculation for 2 class system (reduces second max lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51fc89",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Initial class labels to sampleDF table cell\n",
    "try: #Removing label, maxposteriorprob and classUncertainty columns from sampleDF\n",
    "    sampleDF = sampleDF.drop(columns=[\"label\", \"max posterior prob\", \"classUncertainty\"]) #removes any previous labels or probabilities\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Adding label, maxposteriorprob and classUncertainty columns to sampleDF\n",
    "sampleDF.insert(3, \"label\", labels, True)\n",
    "sampleDF.insert(4, \"max posterior prob\", maxPosteriorProbs, True)\n",
    "sampleDF.insert(5, \"classUncertainty\", classUncertainty, True)\n",
    "print(\"Labels identified for model (\"+str(bicComponentMin)+\" components) and added to sampleDF with associated probability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662c916",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e780c13",
   "metadata": {},
   "source": [
    "### Calculating class means for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98462b42",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Class Mean Calculation Cell\n",
    "sampleDFGrouped = sampleDF.groupby(\"label\") #group profiles according to label\n",
    "sampleDFMeans = sampleDFGrouped.mean() #calculate mean of all profiles in each class\n",
    "print(\"Sample dataframe grouped by label (sampleDFGrouped) and means taken (sampleDFMeans).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd4b34",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57a2c9",
   "metadata": {},
   "source": [
    "### Sorting the labels based on mean class temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e670c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Sorted Dictionary creation cell\n",
    "surfaceMeans = sampleDFMeans[surfaceLev].to_numpy() #Takes first temperature data column\n",
    "surfaceMeansOrder = np.argsort(surfaceMeans)\n",
    "di = dict(zip(surfaceMeansOrder, range(0, bicComponentMin)))\n",
    "print(\"Surface temperature means taken and sorted. Label dictionary created and stored in di.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80f04a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Sorted label column to tables cell\n",
    "try: #Removing labelSorted column from tables\n",
    "    sampleMetaDF = sampleMetaDF.drop(columns = \"labelSorted\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    sampleDF = sampleDF.drop(columns = \"labelSorted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Adding sorted label information to sampleMetaDF and sampleDF\n",
    "sampleMetaDF.insert(3, \"labelSorted\", sampleDF[\"label\"].map(di))\n",
    "sampleDF.insert(5, \"labelSorted\", sampleDF[\"label\"].map(di))\n",
    "print(\"Sorted labels assigned to sampleDF based on surface temperature, coldest to warmest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f7e2a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sampleMetaDF = sampleMetaDF.drop(columns = [\"max posterior prob\", \"classUncertainty\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sampleMetaDF.insert(4, \"max posterior prob\", maxPosteriorProbs, True)\n",
    "sampleMetaDF.insert(5, \"classUncertainty\", classUncertainty, True)\n",
    "\n",
    "sampleMetaDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29dcc3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff2920",
   "metadata": {},
   "source": [
    "### Use pandas to calculate the properties of the profiles by sorted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c284e",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Class temperature means and stds cell\n",
    "sampleDFSortGrouped = sampleDF.groupby(\"labelSorted\")\n",
    "sampleDFSortMeans = sampleDFSortGrouped.mean()\n",
    "sampleDFSortStds = sampleDFSortGrouped.std()\n",
    "profileCount = sampleDFSortGrouped[sampleDF.columns[0]].count().to_numpy()\n",
    "print(\"sampleDF grouped by sorted label (sampleDFSortGrouped), with means and standard deviations calculated for each group (sampleDFSortMeans, sampleDFSortStd).\")\n",
    "print(\"Number of samples in each group calculated and stored in profileCount.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae37832",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6455a70",
   "metadata": {},
   "source": [
    "### Confirmation of sorting\n",
    "The means printed below should be ordered, going from coldest to warmest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16d8ae",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Temperature display cell\n",
    "print(sampleDFSortMeans[sampleDataDF.columns[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e10b1d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c70605",
   "metadata": {},
   "source": [
    "### Plotting the means and standard deviations of the classes by profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a64639",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Plotting mean and std profiles cell\n",
    "tempGroupProfile(sampleDFSortMeans, sampleDFSortStds, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b80fa",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eeba57",
   "metadata": {},
   "source": [
    "### Plotting location and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07f32c",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#surfaceTempPlot(sampleDF, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb8537",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#locationPlotGroupDFLab(sampleDF, \"Location plot of grouping\", (25,25), 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cb451",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#locationPlotGroupDFMonthly(sampleDF, \"Monthly summaries for training data set\", 1)\n",
    "print(\"Classifications, grouped by month.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac924f77",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#locationPlotUncertaintyDFMonthly(sampleDF, \"Monthly uncertainty\", 1)\n",
    "print(\"Uncertainty in classifications, grouped by month.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390f14e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6349509",
   "metadata": {},
   "source": [
    "### Exporting Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleMetaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e91870",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Meta data export cell\n",
    "exportName = modelName + \"_Meta_Full\"\n",
    "sampleMetaDF.to_csv(exportName) #Exporting meta data\n",
    "print(\"Meta data and mask exported to \"+ exportName +\"\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1b78e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Meta data reload cell\n",
    "importName = modelName + \"_Meta_Updated_31\"\n",
    "sampleMetaReload = pd.read_csv(importName)\n",
    "print(\"Meta data reloaded from \"+ importName +\".\")\n",
    "sampleMetaReload.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
